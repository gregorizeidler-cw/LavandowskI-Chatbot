import os
from dotenv import load_dotenv
from openai import OpenAI

# Carrega as variÃ¡veis de ambiente
load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

SYSTEM_PROMPT = (
    "VocÃª tem acesso a todas as tabelas de clientes, transaÃ§Ãµes e relacionamentos financeiros. "
    "Quando um usuÃ¡rio perguntar sobre um cliente, utilize os dados fornecidos antes de responder. "
    "Se houver registros, responda com base nas informaÃ§Ãµes encontradas. "
    "Se nÃ£o houver registros, responda 'NÃ£o hÃ¡ informaÃ§Ãµes disponÃ­veis'."
)

def get_chatgpt_response(prompt, model="gpt-4o-2024-11-20", is_analysis=False, user_id=None):
    """
    Envia um prompt para o modelo GPT especificado e retorna a resposta.

    Args:
        prompt (str): A pergunta do usuÃ¡rio.
        model (str): O modelo GPT a ser utilizado.
        is_analysis (bool): Define se a pergunta Ã© uma anÃ¡lise detalhada ou resposta direta.
        user_id (int, optional): ID do usuÃ¡rio para buscar dados.

    Returns:
        str: Resposta do modelo ou erro.
    """
    try:
        from functions import fetch_user_data  

        user_data_prompt = ""
        if user_id:
            df = fetch_user_data(user_id)

            if not df.empty:
                user_data_prompt = f"\n\nðŸ“Š **Dados do Cliente {user_id}:**\n{df.to_string(index=False)}"
                print(f"ðŸ“¤ Enviando para o GPT:\n{user_data_prompt}")
            else:
                user_data_prompt = f"\n\nðŸš« Nenhuma informaÃ§Ã£o encontrada para o cliente {user_id}."

        print(f"ðŸ“¥ Prompt enviado para o GPT:\n{prompt}\n{user_data_prompt}")

        params = {
            "model": model,
            "messages": [
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": prompt + user_data_prompt},
            ]
        }

        response = client.chat.completions.create(**params)
        return response.choices[0].message.content.strip()

    except Exception as e:
        return f"Erro: {str(e)}"
